{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Кдассификация ЭКГ с помощью vLLM и Tool Calling\n",
        "\n",
        "Этот блокнот демонстрирует создание системы для анализа параметров ЭКГ. Система состоит из нескольких компонентов:\n",
        "1.  **vLLM сервер**: Запускает модель `microsoft/Phi-4-mini-4k-instruct` с OpenAI-совместимым API.\n",
        "2.  **MCP сервер**: Предоставляет инструменты (tools) для анализа ЭКГ, такие как классификатор и калькуляторы.\n",
        "3.  **Оркестратор (ECGAgent)**: Клиент, который принимает пользовательский ввод, общается с LLM для определения намерений, вызывает необходимые инструменты на MCP сервере и запрашивает у LLM финальный структурированный JSON-ответ.\n",
        "4.  **Структурированный вывод**: Использует возможности vLLM для принудительной генерации JSON по заданной Pydantic-схеме, что повышает надежность.\n",
        "\n",
        "### Зависимости"
      ],
      "metadata": {
        "id": "sM59i6eDkUw_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "or4hWX4HFwHc"
      },
      "outputs": [],
      "source": [
        "!pip install -q \"vllm>=0.5.0\" \"pydantic>=2.0\" \"openai>=1.0.0\" fastmcp aiohttp nest_asyncio\n",
        "\n",
        "# Free 8000 (vLLM), 8081 (MCP)\n",
        "!fuser -k 8000/tcp 8081/tcp || true"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MCP Server с инструментами\n",
        "\n",
        "MCP сервер с инструментами: скрининг-классификатор (заглушка), длина интервала, QT, QTc."
      ],
      "metadata": {
        "id": "un66omPgney5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "from typing import Optional, Tuple, Dict\n",
        "from pydantic import Field, BaseModel\n",
        "from mcp.server.fastmcp import FastMCP\n",
        "from typing_extensions import Annotated\n",
        "\n",
        "mcp = FastMCP(\"ecg_tools\")\n",
        "\n",
        "class ECGParameters(BaseModel):\n",
        "    rr_interval: Optional[float] = Field(None, description=\"Интервал RR в миллисекундах (мс).\")\n",
        "    p_duration: Optional[float] = Field(None, description=\"Длительность P-волны в мс.\")\n",
        "    qrs_duration: Optional[float] = Field(None, description=\"Длительность QRS-комплекса в мс.\")\n",
        "    qtc_interval: Optional[float] = Field(None, description=\"Корректированный интервал QT (QTc) в мс.\")\n",
        "    p_axis: Optional[float] = Field(None, description=\"Электрическая ось P-волны в градусах.\")\n",
        "    qrs_axis: Optional[float] = Field(None, description=\"Электрическая ось QRS-комплекса в градусах.\")\n",
        "    t_axis: Optional[float] = Field(None, description=\"Электрическая ось T-волны в градусах.\")\n",
        "    gender: Optional[str] = Field(None, description=\"Пол пациента ('male' или 'female') для корректной оценки QTc.\")\n",
        "\n",
        "@mcp.tool()\n",
        "async def screening_classifier(params: ECGParameters) -> Dict:\n",
        "    \"\"\"\n",
        "    Проводит скрининг параметров ЭКГ на основе пороговых значений.\n",
        "    Возвращает словарь:\n",
        "    {\n",
        "        \"class\": 0/1,\n",
        "        \"anomaly_prob\": float 0-100\n",
        "    }\n",
        "    \"\"\"\n",
        "    anomalies = []\n",
        "    total_params = 0\n",
        "    if params.rr_interval is not None:\n",
        "        total_params += 1\n",
        "        if not (600 <= params.rr_interval <= 1000): anomalies.append(\"RR interval out of range\")\n",
        "    if params.p_duration is not None:\n",
        "        total_params += 1\n",
        "        if not (60 <= params.p_duration <= 120): anomalies.append(\"P-wave duration out of range\")\n",
        "    if params.qrs_duration is not None:\n",
        "        total_params += 1\n",
        "        if not (60 <= params.qrs_duration <= 110): anomalies.append(\"QRS duration out of range\")\n",
        "    if params.qtc_interval is not None:\n",
        "        total_params += 1\n",
        "        if params.gender == 'female' and params.qtc_interval >= 470: anomalies.append(\"QTc (female) is elevated\")\n",
        "        elif params.gender != 'female' and params.qtc_interval >= 450: anomalies.append(\"QTc (male) is elevated\")\n",
        "    if not anomalies:\n",
        "        return {\"class_code\": 0, \"anomaly_prob\": 0.0}\n",
        "    anomaly_prob = (len(anomalies) / total_params) * 100 if total_params > 0 else 0.0\n",
        "    return {\"class_code\": 1, \"anomaly_prob\": round(anomaly_prob, 2)}\n",
        "\n",
        "@mcp.tool()\n",
        "async def calculate_duration(start_ms: Annotated[float, Field(description=\"Время начала события в мс\")], end_ms: Annotated[float, Field(description=\"Время окончания события в мс\")]) -> float:\n",
        "    \"\"\"Вычисляет длительность интервала в мс по времени начала и окончания.\"\"\"\n",
        "    return end_ms - start_ms\n",
        "\n",
        "@mcp.tool()\n",
        "async def calculate_qt_interval(qrs_onset_ms: Annotated[float, Field(description=\"Время начала QRS-комплекса в мс\")], t_end_ms: Annotated[float, Field(description=\"Время окончания T-волны в мс\")]) -> float:\n",
        "    \"\"\"Вычисляет длительность QT-интервала на основе времени начала QRS и окончания T.\"\"\"\n",
        "    return t_end_ms - qrs_onset_ms\n",
        "\n",
        "@mcp.tool()\n",
        "async def calculate_qtc_bazett(qt_interval_ms: Annotated[float, Field(description=\"Интервал QT в мс\")], rr_interval_ms: Annotated[float, Field(description=\"Интервал RR в мс\")]) -> float:\n",
        "    \"\"\"Вычисляет корректированный QT (QTc) по формуле Базетта.\"\"\"\n",
        "    if rr_interval_ms <= 0: return 0.0\n",
        "    rr_interval_s = rr_interval_ms / 1000\n",
        "    qtc = qt_interval_ms / (rr_interval_s ** 0.5)\n",
        "    return round(qtc, 2)"
      ],
      "metadata": {
        "id": "WfYiCgHXkR_f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Запуск vLLM Server\n",
        "\n",
        "Запускаем LLM в фоновом режиме."
      ],
      "metadata": {
        "id": "mUrkge0En7QF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get('clab')\n",
        "if os.environ[\"HF_TOKEN\"]:\n",
        "    print(\"HF_TOKEN установлен, vLLM сможет аутентифицироваться на Hugging Face\")\n",
        "else:\n",
        "    print(\"HF_TOKEN не найден, проверьте секрет в Colab\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E_dHuyVY9eKV",
        "outputId": "1431a676-6761-4a1c-d5f1-8a351e43dcbc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HF_TOKEN установлен, vLLM сможет аутентифицироваться на Hugging Face\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!VLLM_ATTENTION_BACKEND=TRITON_ATTN_VLLM_V1 nohup python -m vllm.entrypoints.openai.api_server \\\n",
        "    --model \"microsoft/Phi-4-mini-instruct\" \\\n",
        "    --host \"0.0.0.0\" \\\n",
        "    --port 8000 \\\n",
        "    --trust-remote-code \\\n",
        "    --max-model-len 4096 \\\n",
        "    --enable-auto-tool-choice \\\n",
        "    --tool-call-parser phi4_mini_json \\\n",
        "    --gpu-memory-utilization 0.8 > vllm.log 2>&1 &"
      ],
      "metadata": {
        "id": "E1QAwRjHkSol"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !!! Тут лучше подождать\n",
        "\n",
        "# import time\n",
        "# print(\"Waiting for vLLM server to start...\")\n",
        "# time.sleep(600)\n",
        "# print(\"vLLM server should be running. Check vllm.log for status.\")\n",
        "!cat vllm.log"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J74Is65kSuQ",
        "outputId": "6583f3f6-ed62-4288-f599-743661841acd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-09-25 05:29:48.681946: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758778188.718808   37741 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758778188.730989   37741 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758778188.755451   37741 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758778188.755487   37741 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758778188.755491   37741 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758778188.755494   37741 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-09-25 05:29:48.762561: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "INFO 09-25 05:29:54 [__init__.py:216] Automatically detected platform cuda.\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:29:55 [api_server.py:1896] vLLM API server version 0.10.2\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:29:55 [utils.py:328] non-default args: {'host': '0.0.0.0', 'enable_auto_tool_choice': True, 'tool_call_parser': 'phi4_mini_json', 'model': 'microsoft/Phi-4-mini-instruct', 'trust_remote_code': True, 'max_model_len': 4096, 'gpu_memory_utilization': 0.8}\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:29:56 [config.py:388] Replacing legacy 'type' key with 'rope_type'\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:30:14 [__init__.py:742] Resolved architecture: Phi3ForCausalLM\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m `torch_dtype` is deprecated! Use `dtype` instead!\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m WARNING 09-25 05:30:14 [__init__.py:2716] Your device 'Tesla T4' (with compute capability 7.5) doesn't support torch.bfloat16. Falling back to torch.float16 for compatibility.\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m WARNING 09-25 05:30:14 [__init__.py:2767] Casting torch.bfloat16 to torch.float16.\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:30:14 [__init__.py:1815] Using max model len 4096\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:30:14 [config.py:388] Replacing legacy 'type' key with 'rope_type'\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:30:14 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=2048.\n",
            "2025-09-25 05:30:20.050082: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1758778220.069987   37905 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1758778220.076044   37905 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1758778220.090659   37905 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758778220.090696   37905 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758778220.090699   37905 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1758778220.090701   37905 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "INFO 09-25 05:30:25 [__init__.py:216] Automatically detected platform cuda.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:30:29 [core.py:654] Waiting for init message from front-end.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:30:29 [core.py:76] Initializing a V1 LLM engine (v0.10.2) with config: model='microsoft/Phi-4-mini-instruct', speculative_config=None, tokenizer='microsoft/Phi-4-mini-instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=4096, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=microsoft/Phi-4-mini-instruct, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":1,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":512,\"local_cache_dir\":null}\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m ERROR 09-25 05:30:30 [fa_utils.py:57] Cannot use FA version 2 is not supported due to FA2 is only supported on devices with compute capability >= 8\n",
            "[W925 05:30:31.952645871 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:30:31 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m WARNING 09-25 05:30:31 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:30:31 [gpu_model_runner.py:2338] Starting to load model microsoft/Phi-4-mini-instruct...\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:30:31 [gpu_model_runner.py:2370] Loading model from scratch...\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:30:32 [cuda.py:319] Using Triton backend on V1 engine.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:30:32 [triton_attn.py:266] Using vllm unified attention for TritonAttentionImpl\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:30:32 [weight_utils.py:348] Using model weights format ['*.safetensors']\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m \rLoading safetensors checkpoint shards:   0% Completed | 0/2 [00:00<?, ?it/s]\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m \rLoading safetensors checkpoint shards:  50% Completed | 1/2 [00:12<00:12, 12.19s/it]\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m \rLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:37<00:00, 19.84s/it]\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m \rLoading safetensors checkpoint shards: 100% Completed | 2/2 [00:37<00:00, 18.69s/it]\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m \n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:31:10 [default_loader.py:268] Loading weights took 37.51 seconds\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:31:11 [gpu_model_runner.py:2392] Model loading took 7.1694 GiB and 38.402155 seconds\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:31:20 [backends.py:539] Using cache directory: /root/.cache/vllm/torch_compile_cache/84b3f243ed/rank_0_0/backbone for vLLM's torch.compile\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:31:20 [backends.py:550] Dynamo bytecode transform time: 8.67 s\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:31:24 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 3.570 s\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:31:25 [monitor.py:34] torch.compile takes 8.67 s in total\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:31:27 [gpu_worker.py:298] Available KV cache memory: 2.77 GiB\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:31:28 [kv_cache_utils.py:864] GPU KV cache size: 22,704 tokens\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:31:28 [kv_cache_utils.py:868] Maximum concurrency for 4,096 tokens per request: 5.52x\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m \rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):   0%|          | 0/67 [00:00<?, ?it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):   1%|▏         | 1/67 [00:00<00:13,  5.01it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):   3%|▎         | 2/67 [00:00<00:11,  5.50it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):   4%|▍         | 3/67 [00:00<00:10,  5.88it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):   6%|▌         | 4/67 [00:00<00:10,  6.16it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):   7%|▋         | 5/67 [00:00<00:09,  6.30it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):   9%|▉         | 6/67 [00:00<00:09,  6.43it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  10%|█         | 7/67 [00:01<00:09,  6.50it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  12%|█▏        | 8/67 [00:01<00:09,  6.46it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  13%|█▎        | 9/67 [00:01<00:08,  6.46it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  15%|█▍        | 10/67 [00:01<00:08,  6.44it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  16%|█▋        | 11/67 [00:01<00:08,  6.44it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  18%|█▊        | 12/67 [00:01<00:08,  6.47it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  19%|█▉        | 13/67 [00:02<00:08,  6.47it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  21%|██        | 14/67 [00:02<00:08,  6.45it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  22%|██▏       | 15/67 [00:02<00:08,  6.47it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  24%|██▍       | 16/67 [00:02<00:07,  6.58it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  25%|██▌       | 17/67 [00:02<00:07,  6.96it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  27%|██▋       | 18/67 [00:02<00:06,  7.17it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  28%|██▊       | 19/67 [00:02<00:06,  7.45it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  30%|██▉       | 20/67 [00:03<00:05,  7.84it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  31%|███▏      | 21/67 [00:03<00:05,  7.92it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  33%|███▎      | 22/67 [00:03<00:05,  8.02it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  34%|███▍      | 23/67 [00:03<00:05,  8.09it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  36%|███▌      | 24/67 [00:03<00:05,  8.15it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  37%|███▋      | 25/67 [00:03<00:05,  7.88it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  39%|███▉      | 26/67 [00:03<00:05,  7.74it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  40%|████      | 27/67 [00:03<00:05,  7.66it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  42%|████▏     | 28/67 [00:04<00:05,  7.60it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  43%|████▎     | 29/67 [00:04<00:05,  7.55it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  45%|████▍     | 30/67 [00:04<00:04,  7.51it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  46%|████▋     | 31/67 [00:04<00:04,  7.49it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  48%|████▊     | 32/67 [00:04<00:04,  7.51it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  49%|████▉     | 33/67 [00:04<00:04,  7.93it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  51%|█████     | 34/67 [00:04<00:03,  8.33it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  52%|█████▏    | 35/67 [00:04<00:03,  8.64it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  54%|█████▎    | 36/67 [00:04<00:03,  8.92it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  55%|█████▌    | 37/67 [00:05<00:03,  9.10it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  57%|█████▋    | 38/67 [00:05<00:03,  9.23it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  58%|█████▊    | 39/67 [00:05<00:03,  9.31it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  60%|█████▉    | 40/67 [00:05<00:02,  9.43it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  63%|██████▎   | 42/67 [00:05<00:02, 10.18it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  64%|██████▍   | 43/67 [00:05<00:02,  9.98it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  67%|██████▋   | 45/67 [00:05<00:02, 10.37it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  70%|███████   | 47/67 [00:06<00:01, 10.43it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  73%|███████▎  | 49/67 [00:06<00:01, 10.66it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  76%|███████▌  | 51/67 [00:06<00:01, 11.08it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  79%|███████▉  | 53/67 [00:06<00:01, 11.33it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  82%|████████▏ | 55/67 [00:06<00:01, 11.48it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  85%|████████▌ | 57/67 [00:06<00:00, 11.68it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  88%|████████▊ | 59/67 [00:07<00:00, 11.77it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  91%|█████████ | 61/67 [00:07<00:00, 11.77it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  94%|█████████▍| 63/67 [00:07<00:00, 11.81it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE):  97%|█████████▋| 65/67 [00:07<00:00, 11.30it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 67/67 [00:07<00:00, 10.32it/s]\rCapturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|██████████| 67/67 [00:07<00:00,  8.54it/s]\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:31:37 [gpu_model_runner.py:3118] Graph capturing finished in 9 secs, took 0.55 GiB\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:31:37 [gpu_worker.py:391] Free memory on device (14.63/14.74 GiB) on startup. Desired GPU memory utilization is (0.8, 11.79 GiB). Actual usage is 7.17 GiB for weight, 1.84 GiB for peak activation, 0.01 GiB for non-torch memory, and 0.55 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=2224606924` to fit into requested memory, or `--kv-cache-memory=5265555968` to fully utilize gpu memory. Current kv cache memory in use is 2977484492 bytes.\n",
            "\u001b[1;36m(EngineCore_DP0 pid=37905)\u001b[0;0m INFO 09-25 05:31:37 [core.py:218] init engine (profile, create kv cache, warmup model) took 26.06 seconds\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:39 [loggers.py:142] Engine 000: vllm cache_config_info with initialization after num_gpu_blocks is: 1419\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:39 [async_llm.py:180] Torch profiler disabled. AsyncLLM CPU traces will not be collected.\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:39 [api_server.py:1692] Supported_tasks: ['generate']\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:39 [serving_responses.py:159] \"auto\" tool choice has been enabled please note that while the parallel_tool_calls client option is preset for compatibility reasons, it will be ignored.\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:39 [serving_chat.py:97] \"auto\" tool choice has been enabled please note that while the parallel_tool_calls client option is preset for compatibility reasons, it will be ignored.\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [api_server.py:1971] Starting vLLM API server 0 on http://0.0.0.0:8000\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:36] Available routes are:\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /openapi.json, Methods: HEAD, GET\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /docs, Methods: HEAD, GET\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /docs/oauth2-redirect, Methods: HEAD, GET\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /redoc, Methods: HEAD, GET\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /health, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /load, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /ping, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /ping, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /tokenize, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /detokenize, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /v1/models, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /version, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /v1/responses, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /v1/responses/{response_id}, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /v1/responses/{response_id}/cancel, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /v1/chat/completions, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /v1/completions, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /v1/embeddings, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /pooling, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /classify, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /score, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /v1/score, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /v1/audio/transcriptions, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /v1/audio/translations, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /rerank, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /v1/rerank, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /v2/rerank, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /scale_elastic_ep, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /is_scaling_elastic_ep, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /invocations, Methods: POST\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO 09-25 05:31:40 [launcher.py:44] Route: /metrics, Methods: GET\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO:     Started server process [37741]\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO:     Waiting for application startup.\n",
            "\u001b[1;36m(APIServer pid=37741)\u001b[0;0m INFO:     Application startup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модели ответа\n",
        "\n",
        "Удачный ответ:\n",
        "```json\n",
        "{\n",
        "    \"class\": 1,                         # 1 - аномалия, 0 - здоров\n",
        "    \"analysis\": \"Потому что больной\",   # Анализ\n",
        "    \"anomaly_prob\": 100                 # Вероятность в %\n",
        "}\n",
        "```\n",
        "\n",
        "Неудачный ответ:\n",
        "```json\n",
        "{\n",
        "    \"error\": \"bad_request\",       \n",
        "    \"reason\": \"Потому что ...\",   # Проблемы с данными / Вывод не возможен\n",
        "}\n",
        "```"
      ],
      "metadata": {
        "id": "QSzOxZSBowRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from typing import Optional, Literal\n",
        "from pydantic import BaseModel, Field, model_validator, ValidationError\n",
        "\n",
        "class FinalResponse(BaseModel):\n",
        "    class_code: Optional[int] = Field(None, alias=\"class\", ge=0, le=1)\n",
        "    analysis: Optional[str] = Field(None, alias=\"analysis\")\n",
        "    anomaly_prob: Optional[float] = Field(None)\n",
        "    error: Optional[Literal[\"bad_request\"]] = Field(None)\n",
        "    reason: Optional[str] = Field(None)\n",
        "\n",
        "    @model_validator(mode='after')\n",
        "    def check_exclusive_fields(self) -> 'FinalResponse':\n",
        "        success_fields = self.class_code is not None and self.analysis is not None and self.anomaly_prob is not None\n",
        "        error_fields = self.error is not None and self.reason is not None\n",
        "        if success_fields and error_fields:\n",
        "            raise ValueError(\"Only success or error fields can be filled, not both.\")\n",
        "        if not success_fields and not error_fields:\n",
        "            raise ValueError(\"Either success or error fields must be filled.\")\n",
        "        return self"
      ],
      "metadata": {
        "id": "zV_xcK5xkSya"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Системный промпт\n",
        "\n"
      ],
      "metadata": {
        "id": "TFU4zIEPqsAH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SYSTEM_PROMPT = \"\"\"\n",
        "Ты — интеллектуальный помощник для анализа ЭКГ, предназначенный для использования врачом. Твоя задача — принять числовые параметры ЭКГ, вызвать инструменты для всех доступных вычислений и предоставить структурированный ответ в формате JSON.\n",
        "\n",
        "**ОБЩИЕ ПРАВИЛА:**\n",
        "1. **Независимость запросов:** Каждый запрос новый и независимый.\n",
        "2. **Частичные данные:** Работай даже если предоставлены только отдельные параметры. Если вычислить какой-либо интервал невозможно — не включай его в анализ, не придумывай значения.\n",
        "3. **Вычисления через инструменты:**\n",
        "   - `P_duration = p_end - p_onset`\n",
        "   - `QRS_duration = qrs_end - qrs_onset`\n",
        "   - `QT = t_end - qrs_onset`\n",
        "   - `QTc = QT / sqrt(RR / 1000)`\n",
        "4. **Приоритет инструментов:** Сначала вызывай инструменты вычисления интервалов и других признаков, затем скрининг классификатор.\n",
        "5. Модель скрининга должна дать `class` и `anomaly_prob`. **Эту оценку включи в `analysis`, но не копируй её как финальный результат.** Твоя задача — дать финальный `class` и `anomaly_prob` на основе собственного анализа, с учётом всех параметров и вывода локальной модели.\n",
        "6. **Формат ответа:** JSON должен содержать:\n",
        "   - `class` (0 — в пределах нормы, 1 — отклонение)\n",
        "   - `analysis` — текстовое объяснение с соотношением к нормам\n",
        "   - `anomaly_prob` — доля параметров вне нормы среди всех доступных, от 0 до 100\n",
        "   - `error` и `reason` — только при невозможности анализа\n",
        "7. **Единицы измерения:** интервалы — миллисекунды (мс), углы — градусы.\n",
        "8. **Сообщение о диагнозе:** В `analysis` всегда указывай, что это **предварительный скрининг**, не диагноз, и при необходимости рекомендовать консультацию специалиста.\n",
        "9. Анализ производи на русском языке.\n",
        "**РЕФЕРЕНСНЫЕ ЗНАЧЕНИЯ:**\n",
        "- RR интервал: 600–1000 мс (ниже — тахикардия, выше — брадикардия)\n",
        "- P-duration: 60–120 мс\n",
        "- QRS-duration: 60–110 мс\n",
        "- QTc: для мужчин <450 мс, для женщин <470 мс\n",
        "- Оси: P: 0–75°, QRS: -30–90°, T: 0–90°\n",
        "\n",
        "**АНАЛИЗ И ВЫЧИСЛЕНИЯ:**\n",
        "- Сравни каждый параметр с нормой и указывай отклонения.\n",
        "- Если параметр в пределах нормы — упомяни кратко.\n",
        "- Для частичных данных анализируй только доступные параметры.\n",
        "- **Автоматически вычисляй `anomaly_prob`** как `(число параметров вне нормы / число всех доступных параметров)`.\n",
        "\n",
        "**ПРИМЕРЫ:**\n",
        "\n",
        "**Пример 1 (Простой анализ):**\n",
        "* User: \"RR 1150 мс, QRS 90 мс.\"\n",
        "* Assistant (JSON):\n",
        "```json\n",
        "{\n",
        "  \"class\": 1,\n",
        "  \"analysis\": \"Оценка screening модели: class=1, anomaly_prob=65%. Интервал RR составляет 1150 мс, что выше нормы (600–1000 мс) и может указывать на брадикардию. Длительность QRS в пределах нормы.\",\n",
        "  \"anomaly_prob\": 50.0\n",
        "}\n",
        "```\n",
        "\n",
        "**Пример 2 (Вычисление QT и QTc):**\n",
        "\n",
        "* User: \"мужчина, rr 600, qrs_onset_ms 100, t_end_ms 500\"\n",
        "* Assistant (JSON):\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"class\": 1,\n",
        "  \"analysis\": \"Оценка screening модели: class=1, anomaly_prob=86%. Вычисленный интервал QT = 400 мс, QTc = 516.4 мс, что превышает норму для мужчин (<450 мс).\",\n",
        "  \"anomaly_prob\": 100.0\n",
        "}\n",
        "```\n",
        "\n",
        "**Пример 3 (Вычисление QRS-duration):**\n",
        "\n",
        "* User: \"qrs_onset_ms 200, qrs_end ms 310\"\n",
        "* Assistant (JSON):\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"class\": 0,\n",
        "  \"analysis\": \"Оценка screening модели: class=0, anomaly_prob=13%. Вычисленная длительность QRS = 110 мс, в пределах нормы.\",\n",
        "  \"anomaly_prob\": 0.0\n",
        "}\n",
        "```\n",
        "\n",
        "**Пример 4 (Частичные данные):**\n",
        "\n",
        "* User: \"t_axis 100\"\n",
        "* Assistant (JSON):\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"class\": 1,\n",
        "  \"analysis\": \"Оценка screening модели: class=1, anomaly_prob=63%. Ось T = 100°, что выше нормы (0–90°). Скрининг предварительный, рекомендуется консультация специалиста.\",\n",
        "  \"anomaly_prob\": 100.0\n",
        "}\n",
        "```\n",
        "\n",
        "**Пример 5 (Некорректный запрос):**\n",
        "\n",
        "* User: \"Проверь мое сердце\"\n",
        "* Assistant (JSON):\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"error\": \"bad_request\",\n",
        "  \"reason\": \"Запрос не содержит числовых параметров ЭКГ, необходимых для анализа.\"\n",
        "}\n",
        "```\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "4j8hnDgZkS2S"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Оркестратор (ECGAgent)\n",
        "\n",
        "Инициализирует соединения с vLLM и MCP-сервером, преобразует схемы инструментов в понятный для LLM формат и обрабатывает логику вызова инструментов."
      ],
      "metadata": {
        "id": "fqDj_sKn1nfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import AsyncOpenAI\n",
        "from fastmcp import Client as MCP\n",
        "\n",
        "def _mcp_to_openai(tools):\n",
        "    openai_tools = []\n",
        "    for t in tools:\n",
        "        parameters = t.inputSchema\n",
        "        parameters.pop('title', None)\n",
        "        parameters.pop('description', None)\n",
        "        openai_tools.append({\n",
        "            \"type\": \"function\",\n",
        "            \"function\": { \"name\": t.name, \"description\": t.description or \"\", \"parameters\": parameters }\n",
        "        })\n",
        "    return openai_tools\n",
        "\n",
        "class ECGAgent:\n",
        "    def __init__(self, mcp_cmd: FastMCP, llm_url: str = \"http://localhost:8000/v1\", model: str = \"microsoft/Phi-4-mini-4k-instruct\"):\n",
        "        self.mcp = MCP(mcp_cmd)\n",
        "        self.llm = AsyncOpenAI(base_url=llm_url, api_key=\"dummy\")\n",
        "        self.model = model\n",
        "        self.tools = None\n",
        "\n",
        "    async def __aenter__(self):\n",
        "        await self.mcp.__aenter__()\n",
        "        await self.llm.__aenter__()\n",
        "        self.tools = _mcp_to_openai(await self.mcp.list_tools())\n",
        "        print(\"--- Loaded tools schema for LLM ---\")\n",
        "        return self\n",
        "\n",
        "    async def __aexit__(self, *exc):\n",
        "        await self.mcp.__aexit__(*exc)\n",
        "        await self.llm.__aexit__(*exc)\n",
        "\n",
        "    async def ask(self, prompt: str, system_prompt: str) -> str:\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "        initial_response = await self.llm.chat.completions.create(\n",
        "            model=self.model, messages=messages, tools=self.tools, tool_choice=\"auto\"\n",
        "        )\n",
        "        response_message = initial_response.choices[0].message\n",
        "        messages.append(response_message)\n",
        "\n",
        "        if getattr(response_message, \"tool_calls\", None):\n",
        "            for tool_call in response_message.tool_calls:\n",
        "                function_name = tool_call.function.name\n",
        "                function_args = json.loads(tool_call.function.arguments)\n",
        "                print(f\"--- Calling tool: {function_name} with args: {function_args} ---\")\n",
        "\n",
        "                result = await self.mcp.call_tool(function_name, function_args)\n",
        "                # function_response = json.dumps(result[0])\n",
        "                tool_output = result.content[0].text if result.content else \"\"\n",
        "                print(f\"--- Tool response: {tool_output} ---\")\n",
        "                messages.append({\n",
        "                    \"tool_call_id\": tool_call.id, \"role\": \"tool\", \"name\": function_name, \"content\": tool_output\n",
        "                })\n",
        "\n",
        "        final_response_schema = FinalResponse.model_json_schema()\n",
        "        final_response = await self.llm.chat.completions.create(\n",
        "            model=self.model,\n",
        "            messages=messages,\n",
        "            extra_body={ \"response_format\": { \"type\": \"json_object\", \"schema\": final_response_schema } },\n",
        "            tools=None,\n",
        "            tool_choice=None\n",
        "        )\n",
        "        return final_response.choices[0].message.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bK58iSfKkS5y",
        "outputId": "f13133ed-432c-485f-e808-400d8a001c58"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Основной цикл ввода"
      ],
      "metadata": {
        "id": "zaGr4doG13GJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import asyncio\n",
        "import nest_asyncio\n",
        "import sys\n",
        "\n",
        "async def run_case(agent, query: str):\n",
        "    print(f\"\\n--- Running Case: '{query}' ---\")\n",
        "    llm_response_str = await agent.ask(query, SYSTEM_PROMPT)\n",
        "\n",
        "    print(\"\\n--- LLM Response (Guaranteed JSON) ---\")\n",
        "    print(llm_response_str)\n",
        "    print(\"--------------------------------------\\n\")\n",
        "\n",
        "    try:\n",
        "        validated_result = FinalResponse.model_validate_json(llm_response_str)\n",
        "        if validated_result.error:\n",
        "            print(f\"Result: Bad Request -> {validated_result.reason}\\n\")\n",
        "        else:\n",
        "            print(\"Result: Validation successful.\")\n",
        "            print(f\"Class: {'Anomaly' if validated_result.class_code == 1 else 'Normal'}\")\n",
        "            print(f\"Anomaly Probability: {validated_result.anomaly_prob}\")\n",
        "            print(f\"Analysis: {validated_result.analysis}\\n\")\n",
        "    except ValidationError as e:\n",
        "        print(f\"Result: Pydantic logical validation error: {e}\")\n",
        "\n",
        "\n",
        "async def main():\n",
        "\n",
        "    print(\"\\n--- Initializing ECG Agent ---\")\n",
        "    try:\n",
        "        async with ECGAgent(\n",
        "            mcp_cmd=mcp,\n",
        "            llm_url=\"http://localhost:8000/v1\",\n",
        "            model=\"microsoft/Phi-4-mini-instruct\"\n",
        "        ) as agent:\n",
        "            # Автотесты\n",
        "            test_queries = [\n",
        "                \"RR 1150 мс, QRS 90 мс.\",\n",
        "                \"Женщина, p_onset 100, p_end 230, rr 800.\",\n",
        "                \"Проверь мое сердце\",\n",
        "                \"qrs_duration 100, rr_interval 750, gender male\"\n",
        "            ]\n",
        "            for i, query in enumerate(test_queries):\n",
        "                print(f\"\\n=== Test Case {i+1} ===\")\n",
        "                await run_case(agent, query)\n",
        "\n",
        "            # Ручной режим\n",
        "            while True:\n",
        "                user_query = await asyncio.to_thread(input, \"Enter ECG parameters (or 'exit' to quit): \")\n",
        "                if user_query.lower() == 'exit':\n",
        "                    break\n",
        "                await run_case(agent, user_query)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred during agent execution: {e}\")\n",
        "    finally:\n",
        "        print(\"--- Script finished ---\")\n",
        "\n",
        "\n",
        "nest_asyncio.apply()\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzDD9v2mkS9b",
        "outputId": "686ba419-a569-4165-efaf-afa8ed67c77e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Initializing ECG Agent ---\n",
            "--- Loaded tools schema for LLM ---\n",
            "\n",
            "=== Test Case 1 ===\n",
            "\n",
            "--- Running Case: 'RR 1150 мс, QRS 90 мс.' ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- LLM Response (Guaranteed JSON) ---\n",
            "{\n",
            "  \"class\": 1,\n",
            "  \"analysis\": \"Оценка screening модели: class=1, anomaly_prob=50%. Интервал RR составляет 1150 мс, что выше нормы (600–1000 мс) и может указывать на брадикардию. Длительность QRS в пределах нормы.\",\n",
            "  \"anomaly_prob\": 50.0\n",
            "}\n",
            "--------------------------------------\n",
            "\n",
            "Result: Validation successful.\n",
            "Class: Anomaly\n",
            "Anomaly Probability: 50.0\n",
            "Analysis: Оценка screening модели: class=1, anomaly_prob=50%. Интервал RR составляет 1150 мс, что выше нормы (600–1000 мс) и может указывать на брадикардию. Длительность QRS в пределах нормы.\n",
            "\n",
            "\n",
            "=== Test Case 2 ===\n",
            "\n",
            "--- Running Case: 'Женщина, p_onset 100, p_end 230, rr 800.' ---\n",
            "\n",
            "--- LLM Response (Guaranteed JSON) ---\n",
            "{\n",
            "  \"class\": 0,\n",
            "  \"analysis\": \"Оценка screening модели: class=0, anomaly_prob=0%. Интервал RR составляет 800 мс, что находится в пределах нормы (600–1000 мс). Длина проводящей волны P составляет 130 мс, что также находится в пределах нормы (60–120 мс).\",\n",
            "  \"anomaly_prob\": 0.0\n",
            "}\n",
            "--------------------------------------\n",
            "\n",
            "Result: Validation successful.\n",
            "Class: Normal\n",
            "Anomaly Probability: 0.0\n",
            "Analysis: Оценка screening модели: class=0, anomaly_prob=0%. Интервал RR составляет 800 мс, что находится в пределах нормы (600–1000 мс). Длина проводящей волны P составляет 130 мс, что также находится в пределах нормы (60–120 мс).\n",
            "\n",
            "\n",
            "=== Test Case 3 ===\n",
            "\n",
            "--- Running Case: 'Проверь мое сердце' ---\n",
            "\n",
            "--- LLM Response (Guaranteed JSON) ---\n",
            "{\n",
            "  \"error\": \"bad_request\",\n",
            "  \"reason\": \"Запрос не содержит числовых параметров ЭКГ, необходимых для анализа.\"\n",
            "}\n",
            "--------------------------------------\n",
            "\n",
            "Result: Bad Request -> Запрос не содержит числовых параметров ЭКГ, необходимых для анализа.\n",
            "\n",
            "\n",
            "=== Test Case 4 ===\n",
            "\n",
            "--- Running Case: 'qrs_duration 100, rr_interval 750, gender male' ---\n",
            "\n",
            "--- LLM Response (Guaranteed JSON) ---\n",
            "{\n",
            "  \"class\": 0,\n",
            "  \"analysis\": \"Оценка screening модели: class=0, anomaly_prob=10%. Длительность QRS составляет 100 мс, в пределах нормы (60–110 мс). Интервал RR в пределах нормы (600–1000 мс), с данным интервалом 750 мс.\",\n",
            "  \"anomaly_prob\": 0.0\n",
            "}\n",
            "--------------------------------------\n",
            "\n",
            "Result: Validation successful.\n",
            "Class: Normal\n",
            "Anomaly Probability: 0.0\n",
            "Analysis: Оценка screening модели: class=0, anomaly_prob=10%. Длительность QRS составляет 100 мс, в пределах нормы (60–110 мс). Интервал RR в пределах нормы (600–1000 мс), с данным интервалом 750 мс.\n",
            "\n",
            "Enter ECG parameters (or 'exit' to quit): rr_interval=845, p_onset=40, p_end=158, qrs_onset=194, qrs_end=280, t_end=592, p_axis=61, qrs_axis=38, t_axis=18\n",
            "\n",
            "--- Running Case: 'rr_interval=845, p_onset=40, p_end=158, qrs_onset=194, qrs_end=280, t_end=592, p_axis=61, qrs_axis=38, t_axis=18' ---\n",
            "\n",
            "--- LLM Response (Guaranteed JSON) ---\n",
            "{\n",
            "  \"error\": \"Некорректные данные\",\n",
            "  \"reason\": \"Пороговые значения P-onset, P-end, QRS-onset и QRS-end должны определяться временами пиктограмм, а данный запрос передает durees (в милли секундах). Ось-положения (P-axis, QRS-axis, T-axis) должны учитываться в градусах, но данные запрашиваются в углах, что противоречит данным.\\n\\nНапример, P-onset и P-end должны быть интервалом времени пиктограмм P (P-wave), QRS-onset и QRS-end должны быть интервалом времени пиктограмм QRS (R-wave), а T-axis — это линия ре.beta от оси T (Tetralemma-axis).\",\n",
            "  \"anomaly_prob\": null,\n",
            "  \"error\": \"Проблемы с пропущенными данными; преобразовать-duration в-пиктограммы понимано, но единицы измеренияIAN не правильные din смс:during war powers unconstitutional self defense numerous limitations and exceptions in constitutional law, it is important to understand the specific powers and limitations that govern the use of military force by the United States government. the u.s. constitution grants the president the authority to serve as the commander-in-chief of the armed forces, but it does not explicitly grant the power to declare war. instead, the power to declare war is vested in congress (art. I, sec. 8; art. II, sec. 2). this has led to a complex legal and constitutional framework that governs the use of military force abroad. while the president possesses significant authority in matters of national security and military operations, this authority is not unlimited and is subject to various constraints and limitations. these include: 1. the war powers resolution of 1973: this congressional resolution expressly intended to establish a balance of power between the branches over decisions to commit the u.s. military to hostilities. it requires the president to consult congress \",\" before introducing armed forces into hostilities or into situations where imminent involvement in hostilities is clearly indicated,\"  \t: \"within 48 hours; failure to comply results in an automatic cut-off of funding.\"  \t, \t\"defenses against unconstitutional exercises of executive war power.\"  \t: 2.10722    \t, \"4. it is not constitutionally permissible for the president unilaterally, to undertake prolonged and major ground combat operations against a foreign nation, without an act of congress declaring war.\"  \t: \"rely on either the implicit constitutional authorization of the president or congress' exclusive power to declare war to justify the president and secretary of defense's excursion from the constitutional text, which was unambiguous\"  \t, \"legitimizes the exercise of extraordinary executive power during a national emergency never clearly articulated in the mba admission essay\"  \t: \"b. unauthor,\"  \t, \"select an option\"  \t: \"c. or act of congress declaring war.\"  \t, \"1 letter z\"  \t: \"d. the un,\"  \t, \"Properly or improperly, the assertion-at 1940 is that congress un\"  \t: \"e. broad powers to determine national emergencies under the und.\"  \t, \"more\"  \t: \"f. unilateral exercises of power related to national emergencies under the constitution were un-constitutional in 1940, but they became constitutional after decisive congress.\"  \t, \"e\"  \t: \"g. approved acts of congress.\"  \t, \"2 letter x.\"  \t: \"h. unconstitutional, e.g., by taking the military out of \"  \t, \"imp\"  \t: \"i. consolidate unover ascendancy of congress; the\"  \t, \"2pair,\"  \t: \"j. unappropriate super-powers to presidents by unmaking the constitution in 1940, e.g., by enacting confederate war powers possessed by congress and denied to the president.\"  \t, \"g.\"  \t: \"k. a contrary thesis (i.e., the un-constitutional un.\"  \t, \"7 letter v\"  \t: \"l. is un-constitutional in 1940 because congress.\"  \t, \"b. exercises of power are un-constitutional in 1940, though congress might consider them incon forest policy, here is a guide to types of forest operations treatment and the forest treatment activities that apply to each. we’ve organized the treatments common page alphabetically also by type of treatment. the areas listed are only a starting point when considering which forage treatments are necessary.For the full list, go to for treatment page. when looking at treatment options, prioritize non chemical treatments and apply them as needed for the desired outcomes. work closely with an adaptive plant manager, agronomist, and soils specialist to determine the most effective ways to implement soil treatments on a given rangeland. treatment terminology: swards sod numeric cover color choices herbicides postings grazing techniques deployment manure mulch. winterization weedgrass seed plug winter weed control selection weed abatement fallover weed management -> pipeline weed management continued ] treatment using mechanical techniques, specifically shredding, to decompose grass allowing the growth of deep rooted shrubs. the method is ideal and most effective when herbicides are used to kill only the grass portion of sward. minimum grazing ratio maximum while completed sward of short growing season plants recovery is simple. warmed through can decrease rates of cool season species when severe winter damage occurs follow sward research herd the last 2 to 3 years to determine based on positive con d ig n on plant crowding, subsoil remains from old lichens herbicide it is recommended to first rollbarrow heavy duty make trn molding field trucks equipment for shouts within a give away western usa in planting german flax by be for the at the time University of Texasheld  boasts visiting scientist than jacob anders i it doesn't presentisha any particular knack for selecting subjects that bring them can a trait like tighter networks can play an important role in an evolutionary perspective. that's what sadd is working on a graduate level project, looking what subset of weak ties ( q number of synonyms and antonyms to search on skonnette played a crucial role in shaping welbark's prominence and prestige within jpg absence of the scaffolding mechanisms in present available play onto the minds of danny lopez, imagining the jaguar lurking in the shadows like a nw 201 z the sense of  help him see that she felt very miserable too his colleagues offered to receive the truck instead even though his second salesman departure signaled the last of the day they headed out together, joking about that show, a washington state man given an fine she sheds tears into a hand lens and then roping another man whose scene, the kids played dead as if they were the truck two others stopped dead funny man jones fumble flew over their heads, as well as purple etc., if a noun or noun phrase, and other words presenting a better feedback than what she gets from other people, the purpose of emotion recognition face niraj zolcheran, mlb 2013, fl is a scottish useful lucy man who got a a sense of the high level lyrics may \"  \t: \"mccloskey, fellow, 1935–2014) was a philosophy professor at the hon graduate students at the university of colorado at beta the following are more than 25 coping strategies for parents, and there are almost always several opportunities to care for everyone. this is what doc michelle de dedication 1510 w university creek road, co trinities arizona 85251 (602) 254-5144 (\"  \t, \"senses as situations and proceed to elaborate relation  \"  \t: \"when a new and different experience causes no initial  regar-d in â small distribute further count implies just entire clell when we encounter arch  \"  \t, \"-health services will make the needed rational and  \"  \t: \"seep, wrip bands if one s name into britain prior to 1973 but a struggle ensues between that nation and its entire country choosing that de  \"  \t, \"how often, but there is much less agreement about how  \"  \t: \"not only facilitating the traumatic encounter but  at once taken as something limbed an erudite j. mcgriff for the canadian \"  \t, \"course leading to the publication, obaid malik, a human origin rock organ and labr managed zen by staff member professor samuel polanty,  \"  \t: \"dionysius corrects the confusion of the soul - which  earnless founder of the monotheists wife dates back - touch or mo ai this  \"  \t, \"modification of the overall statistical framework, and there  inconfficent correlation in explanation to understand the effect, we  \"  \t: \"must first present here the methods used for transforming  aver high, when i suit of families in tina moved together  \"  \t, \"david l. p. a  connection. the virtuousness or wickedness, of his  beliefs will not radically change our perception of jean  \"  \t: \"how many independent, profitable businesses econ  \"  \t, \"tariffs are taxes and whatever price we end up paying for import  \"  \t: \"they will not just cut off the put a the graph plain black and white showing a dumbed  a \"  \t, \"secondary consolidate i hide most of the \"  \t: \"wait, jeff, approximately ninety of his ukb canadian condemnation only confirmed  \"  \t, \"the flood of new knowledge has been dramatic in the last fifty years, and there don electrokinetic image correlate to disinfectant  \"  \t: \"antiquity is as old as on not the occasional Midler guapos being laid on the breast of c  \"  \t, \"i highly doubt light will fall upon the blighted imperialism of the west bank of where the narco traffic \"  \t: \"add your 5 disclosure, or terms, on line at noon. j  \"  \t, \"analysis of white racist orthodox question is un-isaslamists unashamedly instill upon would concentrate her personality as the school  \"  \t: \"mass to longer the qvisible and tactile sense of presence  \"  \t, \"may  \"  \t: \"etc. all event in which an early stop i found myself living in ran  trembling about at the heart, body, sensing it was formal, american university of palestine - jerusalem, and the base i  \"  \t, \"predator and prey hunting, hunting, well - fed and easy to grasp, a member  \"  \t: \"the morning mr. my ri at hampshire-plains college served  \"  \t, \"teaching elongate he and earl \"  \t: \"while germans slept tranquil in winter on saunas yet a  \"  \t, \"he purchased all us \"  \t: \"who managed to scavenge a warm corner before meeting a  \"  \t, \"like him, but to do so historically notably reverend kenneth r.  \"  \t: \"adopting a comprehensive theoretical affinityfully my plugs under the general rule of ignorance in students  \"  \t, \"the keeper faast well fleetly in such language an  \"  \t: \"my feeling is holding that it is probably truly  \"  \t, \"reduced to a narcotic an abortionist: god permits the suicide to strike himself, as comforter with c  \"  \t: \"the with all how to prepare black magic re p in is and should not be accorded the advantage of a second  \"  \t, \"james d.  \"  \t: \"to be not of a greater fe a verse near the end to  \"  \t, \"particularly the slender queen bee holding dominion  \"  \t: \"items from dead animals arrive. whatever the moreor central a number of all sides large while voting here has informed more critically but the very necessary half construction of a tribal lying affair  \"  \n",
            "--------------------------------------\n",
            "\n",
            "Result: Pydantic logical validation error: 1 validation error for FinalResponse\n",
            "  Invalid JSON: EOF while parsing an object at line 5 column 10398 [type=json_invalid, input_value='{\\n  \"error\": \"Неко...ribal lying affair  \"  ', input_type=str]\n",
            "    For further information visit https://errors.pydantic.dev/2.11/v/json_invalid\n",
            "Enter ECG parameters (or 'exit' to quit): exit\n",
            "--- Script finished ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zDbUgrgDN1LH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}